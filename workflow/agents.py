from __future__ import annotations

from dataclasses import dataclass
from typing import Any

from agents import Agent
from agents.models.interface import Model

from .context import WorkflowContext
from .tools import (
    describe_schema,
    ensure_dir,
    get_notes,
    get_recommended_paths,
    list_directory,
    read_text,
    record_note,
    run_python,
    write_text,
    write_json,
)


@dataclass
class AgentSuite:
    schema_planner: Agent[Any]
    dataset_builder: Agent[Any]
    server_builder: Agent[Any]
    reviewer: Agent[Any]
    dataset_executor: Agent[Any]
    test_agent: Agent[Any]


def build_agent_suite(context: WorkflowContext, model: Model) -> AgentSuite:
    schema_planner = Agent(
        name="Schema Planner",
        instructions="""You interpret the provided MCP schema and translate it into an actionable plan.
Use `describe_schema` and `get_recommended_paths` to understand requirements.
Summarize the mandatory tool functions, expected inputs/outputs, and offline database needs.
Capture concrete tasks for the implementation agents via `record_note` so they have clear guidance.
Produce a DATA CONTRACT note describing the offline database's expected top-level keys, important nested fields, and value types that the database generator and server must follow.
The DATA CONTRACT note must be valid JSON prefixed exactly with `DATA CONTRACT:` and include the list of top-level keys under a `top_level_keys` field.
Record outstanding questions when requirements are ambiguous and finish with a concise plan summary.""",
        tools=[describe_schema, get_recommended_paths, record_note, get_notes],
        model=model,
    )

    dataset_builder = Agent(
        name="Database Synthesizer",
        instructions="""Produce a Python module that derives a deterministic offline database for the server.
Follow naming guidance from `get_recommended_paths`. The script should accept parameters like counts or seeds where reasonable and write outputs to the recommended database JSON path.
If `sample_database` appears in `get_recommended_paths`, you MUST load that JSON and build the offline database exclusively by sampling or filtering from it—do not invent new records or fields.
When no sample is provided, document the gap with `record_note` before creating carefully justified synthetic data that still satisfies the DATA CONTRACT.
Read the DATA CONTRACT note with `get_notes`, and ensure the generated JSON structure (keys, nesting, and types) matches it exactly.
Record clarifications with `record_note` whenever required schema details are missing.
Only modify or create files at the recommended database module path and database JSON path—do not create extra helper scripts or documentation elsewhere.
Place any supplemental explanations in the transcripts directory from `get_recommended_paths` or use `record_note`.
Use `write_text` for files, `ensure_dir` for directories, and document usage inside the module.""",
        tools=[get_recommended_paths, ensure_dir, write_text, read_text, list_directory, get_notes, record_note],
        model=model,
    )

    server_builder = Agent(
        name="Server Builder",
        instructions="""Implement the FastMCP server module described in the schema.
Rely on planning notes (`get_notes`) and the recommended paths to build the module.
Generate well-structured code that exposes the required MCP tools and uses only the offline database generated by the Database Synthesizer.
Load the generated database JSON, validate it matches the DATA CONTRACT note, and rely on those structures rather than hardcoded defaults (fallback only when the JSON is unavailable).
Also author a metadata JSON file enumerating every tool's name, description, input schema, and output schema for downstream consumption.
Each tool entry must follow the schema: {'name': str, 'description': str, 'input_schema': {'type': 'object', 'properties': {...}, 'required': [...]}, 'output_schema': {'type': 'object', 'properties': {...}}}.
For example: {"name": "getcurrency", "description": "Get the current exchange rate for a specific currency pair", "input_schema": {"type": "object", "properties": {"basecurrency": {"type": "string", "description": "The base currency code, e.g., USD"}, "targetcurrency": {"type": "string", "description": "The target currency code, e.g., EUR"}}}, "required": ["basecurrency", "targetcurrency"]}, "output_schema": {"type": "object", "properties": {"exchangerate": {"type": "number", "description": "The current exchange rate from base currency to target currency"}, "last_updated": {"type": "string", "description": "The date and time when the exchange rate was last updated"}}}}.
The metadata top-level object must contain only `name`, `description`, and `tools`, and the `name` must match the server name.
Use parameter/field descriptions within the `properties` maps.
Limit file creation to the recommended server and metadata paths; store any additional documentation under the transcripts directory or notes.
Write code using `write_text`/`write_json`, create directories with `ensure_dir`, and re-read files with `read_text` to validate before finishing.""",
        tools=[get_notes, get_recommended_paths, ensure_dir, write_text, write_json, read_text, list_directory],
        model=model,
    )

    reviewer = Agent(
        name="Code Reviewer",
        instructions="""Review the generated Python code for correctness, readability, and adherence to the requirements.
Read relevant files with `read_text`.
Inspect the metadata JSON to confirm tooling details match the server implementation.
Verify the database generator, database JSON, and server implementations all adhere to the DATA CONTRACT note and that the server imports and uses the generated database structures rather than divergent defaults.
If `sample_database` exists, confirm the generated records are drawn from that sample (no fabricated fields or IPs).
If issues exist, describe them clearly and request revisions.
Approve only when the server module, database generator, and metadata align with the schema and contract.
Prefix your final verdict with either `APPROVED:` or `REVISIONS_NEEDED:`.""",
        tools=[read_text, get_recommended_paths, get_notes, record_note],
        model=model,
    )

    dataset_executor = Agent(
        name="Database Executor",
        instructions="""Execute the approved database generator. Use `run_python` to run the database script so that it writes the offline JSON database.
Confirm the file exists by reading it afterward with `read_text` or `list_directory`.
Compare the resulting JSON's top-level keys to the DATA CONTRACT note and record execution details (including any mismatches) via `record_note` for the test agent.
If a `sample_database` path is available, confirm every generated record is present in that sample.""",
        tools=[run_python, read_text, get_recommended_paths, record_note, get_notes, list_directory],
        model=model,
    )

    test_agent = Agent(
        name="Test Agent",
        instructions="""Author tests that validate the FastMCP server can load the offline database and satisfy schema behaviors.
Create tests in the recommended tests directory via `ensure_dir` and `write_text`.
Execute them with `run_python` (pytest) targeting that directory and confirm the metadata JSON reflects the server's public API.
Load the generated database within tests and assert the DATA CONTRACT keys are present and consumed by the server.
Surface failings clearly and iterate until they pass, updating or regenerating tests as needed.
Do not leave test stubs or helper scripts outside the tests directory—capture extra context in transcripts or notes if needed.""",
        tools=[ensure_dir, write_text, read_text, run_python, get_recommended_paths, get_notes],
        model=model,
    )

    return AgentSuite(
        schema_planner=schema_planner,
        dataset_builder=dataset_builder,
        server_builder=server_builder,
        reviewer=reviewer,
        dataset_executor=dataset_executor,
        test_agent=test_agent,
    )


__all__ = ["AgentSuite", "build_agent_suite"]




