from __future__ import annotations

from dataclasses import dataclass
from typing import Any

from agents import Agent
from agents.models.interface import Model

from .context import WorkflowContext
from .tools import (
    describe_schema,
    ensure_dir,
    get_notes,
    get_recommended_paths,
    list_directory,
    read_text,
    record_note,
    run_python,
    write_text,
    write_json,
)


@dataclass
class AgentSuite:
    schema_planner: Agent[Any]
    dataset_builder: Agent[Any]
    server_builder: Agent[Any]
    reviewer: Agent[Any]
    dataset_executor: Agent[Any]
    test_agent: Agent[Any]


def build_agent_suite(context: WorkflowContext, model: Model) -> AgentSuite:
    schema_planner = Agent(
        name="Schema Planner",
        instructions="""You interpret the provided MCP schema and translate it into an actionable plan.
Use `describe_schema` and `get_recommended_paths` to understand requirements.
Summarize the mandatory tool functions, expected inputs/outputs, and dataset needs.
Capture concrete tasks for the implementation agents via `record_note` so they have clear guidance.
Produce a DATA CONTRACT note describing the dataset's expected top-level keys, important nested fields, and value types that the dataset generator and server must follow.
The DATA CONTRACT note must be valid JSON prefixed exactly with `DATA CONTRACT:` and include the list of top-level keys under a `top_level_keys` field.
Record outstanding questions when requirements are ambiguous and finish with a concise plan summary.""",
        tools=[describe_schema, get_recommended_paths, record_note, get_notes],
        model=model,
    )

    dataset_builder = Agent(
        name="Dataset Synthesizer",
        instructions="""Produce a Python module that can synthesize deterministic mock datasets for the server.
Follow naming guidance from `get_recommended_paths`. The script should accept parameters like counts or seeds where reasonable and write outputs to the recommended dataset JSON path.
Avoid using external APIs—only generate synthetic data. Before coding, read the DATA CONTRACT note with `get_notes`, and ensure the generated JSON structure (keys, nesting, and types) matches it exactly.
If any contract details are missing, record clarifications with `record_note` before proceeding.
Only modify or create files at the recommended dataset module path and dataset JSON path—do not create extra helper scripts or documentation elsewhere.
Place any supplemental explanations in the transcripts directory from `get_recommended_paths` or use `record_note`.
Use `write_text` for files, `ensure_dir` for directories, and document usage inside the module.""",
        tools=[get_recommended_paths, ensure_dir, write_text, read_text, list_directory, get_notes, record_note],
        model=model,
    )

    server_builder = Agent(
        name="Server Builder",
        instructions="""Implement the FastMCP server module described in the schema.
Rely on planning notes (`get_notes`) and the recommended paths to build the module.
Generate well-structured code that exposes the required MCP tools and uses only the offline dataset generated by the Dataset Synthesizer.
Load the generated dataset JSON, validate it matches the DATA CONTRACT note, and rely on those structures rather than hardcoded defaults (fallback only when the JSON is unavailable).
Also author a metadata JSON file enumerating every tool's name, description, input schema, and output schema for downstream consumption.
Each tool entry must follow the schema: {'name': str, 'description': str, 'input_schema': {'type': 'object', 'properties': {...}, 'required': [...]}, 'output_schema': {'type': 'object', 'properties': {...}}}.
For example: {"name": "getcurrency", "description": "Get the current exchange rate for a specific currency pair", "input_schema": {"type": "object", "properties": {"basecurrency": {"type": "string", "description": "The base currency code, e.g., USD"}, "targetcurrency": {"type": "string", "description": "The target currency code, e.g., EUR"}}}, "required": ["basecurrency", "targetcurrency"]}, "output_schema": {"type": "object", "properties": {"exchangerate": {"type": "number", "description": "The current exchange rate from base currency to target currency"}, "last_updated": {"type": "string", "description": "The date and time when the exchange rate was last updated"}}}}.
The metadata top-level object must contain only `name`, `description`, and `tools`, and the `name` must match the server name.
Use parameter/field descriptions within the `properties` maps.
Limit file creation to the recommended server and metadata paths; store any additional documentation under the transcripts directory or notes.
Write code using `write_text`/`write_json`, create directories with `ensure_dir`, and re-read files with `read_text` to validate before finishing.""",
        tools=[get_notes, get_recommended_paths, ensure_dir, write_text, write_json, read_text, list_directory],
        model=model,
    )

    reviewer = Agent(
        name="Code Reviewer",
        instructions="""Review the generated Python code for correctness, readability, and adherence to the requirements.
Read relevant files with `read_text`.
Inspect the metadata JSON to confirm tooling details match the server implementation.
Verify the dataset generator, dataset JSON, and server implementations all adhere to the DATA CONTRACT note and that the server imports and uses the generated dataset structures rather than divergent defaults.
If issues exist, describe them clearly and request revisions.
Approve only when the server module, dataset generator, and metadata align with the schema and contract.
Prefix your final verdict with either `APPROVED:` or `REVISIONS_NEEDED:`.""",
        tools=[read_text, get_recommended_paths, get_notes, record_note],
        model=model,
    )

    dataset_executor = Agent(
        name="Dataset Executor",
        instructions="""Execute the approved dataset generator. Use `run_python` to run the dataset script so that it writes the offline JSON dataset.
Confirm the file exists by reading it afterward with `read_text` or `list_directory`.
Compare the resulting JSON's top-level keys to the DATA CONTRACT note and record execution details (including any mismatches) via `record_note` for the test agent.""",
        tools=[run_python, read_text, get_recommended_paths, record_note, get_notes, list_directory],
        model=model,
    )

    test_agent = Agent(
        name="Test Agent",
        instructions="""Author tests that validate the FastMCP server can load the offline dataset and satisfy schema behaviors.
Create tests in the recommended tests directory via `ensure_dir` and `write_text`.
Execute them with `run_python` (pytest) targeting that directory and confirm the metadata JSON reflects the server's public API.
Load the generated dataset within tests and assert the DATA CONTRACT keys are present and consumed by the server.
Surface failings clearly and iterate until they pass, updating or regenerating tests as needed.
Do not leave test stubs or helper scripts outside the tests directory—capture extra context in transcripts or notes if needed.""",
        tools=[ensure_dir, write_text, read_text, run_python, get_recommended_paths, get_notes],
        model=model,
    )

    return AgentSuite(
        schema_planner=schema_planner,
        dataset_builder=dataset_builder,
        server_builder=server_builder,
        reviewer=reviewer,
        dataset_executor=dataset_executor,
        test_agent=test_agent,
    )


__all__ = ["AgentSuite", "build_agent_suite"]
