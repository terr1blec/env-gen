# å‘½ä»¤è¡Œå‚æ•°å‚è€ƒ

## åŸºæœ¬ç”¨æ³•

```bash
python main.py [OPTIONS]
```

## å‚æ•°åˆ—è¡¨

### å¿…éœ€å‚æ•°

è™½ç„¶æ‰€æœ‰å‚æ•°éƒ½æœ‰é»˜è®¤å€¼ï¼Œä½†é€šå¸¸ä½ éœ€è¦æŒ‡å®š schema æ–‡ä»¶ï¼š

#### `--schema`
- **ç±»å‹**: Path
- **é»˜è®¤å€¼**: `mcp_servers\Time & Calendar\cf_1629.google-calendar-mcp_google-calendar_labeled.json`
- **è¯´æ˜**: MCP schema JSON æ–‡ä»¶çš„è·¯å¾„
- **ç¤ºä¾‹**: 
  ```bash
  python main.py --schema "mcp_servers/Social_Media/twitter.json"
  ```

### è¾“å‡ºé…ç½®

#### `--output-dir`
- **ç±»å‹**: Path
- **é»˜è®¤å€¼**: `generated`
- **è¯´æ˜**: ç”Ÿæˆçš„æ¨¡å—å’Œç¦»çº¿æ•°æ®åº“çš„å­˜å‚¨ç›®å½•
- **ç¤ºä¾‹**:
  ```bash
  python main.py --output-dir "my_output"
  ```

#### `--transcripts-dir`
- **ç±»å‹**: Path
- **é»˜è®¤å€¼**: `transcripts`
- **è¯´æ˜**: Agent è®°å½•å’Œè¾…åŠ©ä¿¡æ¯çš„å­˜å‚¨ç›®å½•
- **ç¤ºä¾‹**:
  ```bash
  python main.py --transcripts-dir "my_transcripts"
  ```

### æ¨¡å‹é…ç½®

#### `--model`
- **ç±»å‹**: String
- **é»˜è®¤å€¼**: `deepseek/deepseek-chat` (æˆ–ç¯å¢ƒå˜é‡ `WORKFLOW_MODEL`)
- **è¯´æ˜**: ç”¨äºæ‰€æœ‰ Agent çš„ LLM æ¨¡å‹æ ‡è¯†ç¬¦
- **æ”¯æŒçš„æ¨¡å‹**: 
  - `deepseek/deepseek-chat`
  - `openai/gpt-4`
  - `anthropic/claude-3-5-sonnet-20241022`
  - å…¶ä»– LiteLLM æ”¯æŒçš„æ¨¡å‹
- **ç¤ºä¾‹**:
  ```bash
  python main.py --model "openai/gpt-4"
  ```

#### `--api-key`
- **ç±»å‹**: String
- **é»˜è®¤å€¼**: None (ä»ç¯å¢ƒå˜é‡è·å–)
- **è¯´æ˜**: LiteLLM API å¯†é’¥ï¼Œä¼šå›é€€åˆ°ç¯å¢ƒå˜é‡ `DEEPSEEK_API_KEY` / `LITELLM_API_KEY` / `API_KEY`
- **ç¤ºä¾‹**:
  ```bash
  python main.py --api-key "your-api-key-here"
  ```

#### `--config`
- **ç±»å‹**: Path
- **é»˜è®¤å€¼**: `workflow/config/default.yaml`
- **è¯´æ˜**: å·¥ä½œæµé…ç½® YAML æ–‡ä»¶è·¯å¾„
- **ç¤ºä¾‹**:
  ```bash
  python main.py --config "my_config.yaml"
  ```

### æ‰§è¡Œæ§åˆ¶

#### `--max-turns`
- **ç±»å‹**: Integer
- **é»˜è®¤å€¼**: `24`
- **è¯´æ˜**: å…è®¸å·¥ä½œæµçš„æœ€å¤§ Agent è½®æ¬¡
- **å»ºè®®å€¼**: 
  - ç®€å• schema: 15-20
  - ä¸­ç­‰å¤æ‚åº¦: 20-30
  - å¤æ‚ schema: 30-50
- **ç¤ºä¾‹**:
  ```bash
  python main.py --max-turns 30
  ```

### å¯è§‚æµ‹æ€§é…ç½® ğŸ†•

#### `--no-progress`
- **ç±»å‹**: Flag
- **é»˜è®¤å€¼**: False (è¿›åº¦å¯è§†åŒ–é»˜è®¤å¯ç”¨)
- **è¯´æ˜**: ç¦ç”¨å®æ—¶è¿›åº¦å¯è§†åŒ–ï¼Œä½¿ç”¨ç®€å•æ–‡æœ¬è¾“å‡º
- **é€‚ç”¨åœºæ™¯**:
  - CI/CD ç¯å¢ƒ
  - ç»ˆç«¯ä¸æ”¯æŒ ANSI é¢œè‰²
  - éœ€è¦ç®€æ´æ—¥å¿—è¾“å‡º
- **ç¤ºä¾‹**:
  ```bash
  # ç¦ç”¨è¿›åº¦å¯è§†åŒ–
  python main.py --no-progress
  
  # é»˜è®¤å¯ç”¨ï¼ˆæ— éœ€å‚æ•°ï¼‰
  python main.py
  ```

## å¸¸ç”¨å‘½ä»¤ç»„åˆ

### 1. åŸºæœ¬å¼€å‘ä½¿ç”¨
```bash
python main.py \
  --schema "mcp_servers/Time & Calendar/google-calendar.json"
```

### 2. ç”Ÿäº§ç¯å¢ƒï¼ˆç¦ç”¨å¯è§†åŒ–ï¼‰
```bash
python main.py \
  --schema "path/to/schema.json" \
  --no-progress \
  --max-turns 30 \
  --output-dir "production_output"
```

### 3. è‡ªå®šä¹‰é…ç½®
```bash
python main.py \
  --schema "path/to/schema.json" \
  --config "production_config.yaml" \
  --api-key "your-api-key"
```

### 4. ä½¿ç”¨ä¸åŒæ¨¡å‹
```bash
python main.py \
  --schema "path/to/schema.json" \
  --model "openai/gpt-4" \
  --api-key "sk-..."
```

### 5. è°ƒè¯•æ¨¡å¼ï¼ˆæ›´å¤šè½®æ¬¡ï¼‰
```bash
python main.py \
  --schema "path/to/schema.json" \
  --max-turns 50 \
  --enable-progress
```

## ç¯å¢ƒå˜é‡

ä»¥ä¸‹ç¯å¢ƒå˜é‡ä¼šå½±å“å·¥ä½œæµè¡Œä¸ºï¼š

### API é…ç½®
- `DEEPSEEK_API_KEY`: DeepSeek API å¯†é’¥ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
- `LITELLM_API_KEY`: LiteLLM API å¯†é’¥
- `API_KEY`: é€šç”¨ API å¯†é’¥ï¼ˆä¼˜å…ˆçº§æœ€ä½ï¼‰
- `DEEPSEEK_BASE_URL`: DeepSeek API åŸºç¡€ URL
- `LITELLM_BASE_URL`: LiteLLM API åŸºç¡€ URL
- `BASE_URL`: é€šç”¨ API åŸºç¡€ URL

### å·¥ä½œæµé…ç½®
- `WORKFLOW_MODEL`: é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¯è¢« `--model` è¦†ç›–ï¼‰
- `WORKFLOW_MAX_TURNS`: æœ€å¤§è½®æ¬¡ï¼ˆå¯è¢« `--max-turns` è¦†ç›–ï¼‰
- `WORKFLOW_PYTHON_TIMEOUT`: Python æ‰§è¡Œè¶…æ—¶ï¼ˆç§’ï¼‰
- `WORKFLOW_MAX_REVIEW_CYCLES`: æœ€å¤§å®¡æŸ¥å¾ªç¯æ¬¡æ•°
- `WORKFLOW_LOG_LEVEL`: æ—¥å¿—çº§åˆ«ï¼ˆDEBUG/INFO/WARNING/ERRORï¼‰
- `WORKFLOW_CONSOLE_LOGS`: æ˜¯å¦è¾“å‡ºæ§åˆ¶å°æ—¥å¿—ï¼ˆtrue/falseï¼‰

### ç¤ºä¾‹ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
```bash
export DEEPSEEK_API_KEY="your-key"
export WORKFLOW_MODEL="deepseek/deepseek-chat"
export WORKFLOW_MAX_TURNS=30

python main.py --schema "path/to/schema.json"
```

## è·å–å¸®åŠ©

æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‚æ•°ï¼š

```bash
python main.py --help
```

è¾“å‡ºï¼š
```
usage: main.py [-h] [--schema SCHEMA] [--output-dir OUTPUT_DIR]
               [--transcripts-dir TRANSCRIPTS_DIR] [--model MODEL]
               [--max-turns MAX_TURNS] [--prompt PROMPT]
               [--api-key API_KEY] [--config CONFIG]
               [--enable-progress] [--no-progress]

Run the MCP offline server generation workflow.

optional arguments:
  -h, --help            show this help message and exit
  --schema SCHEMA       Path to the MCP schema JSON file.
  --output-dir OUTPUT_DIR
                        Directory where generated modules and offline
                        databases will be stored.
  --transcripts-dir TRANSCRIPTS_DIR
                        Directory where agent transcripts can be written by
                        downstream tooling.
  --model MODEL         OpenAI model identifier for all agents.
  --max-turns MAX_TURNS
                        Maximum number of agent turns to allow for the
                        workflow.
  --prompt PROMPT       High-level goal shared across agents during the
                        workflow.
  --api-key API_KEY     Override API key passed to LiteLLM (falls back to
                        DEEPSEEK_API_KEY / API_KEY environments).
  --config CONFIG       Path to workflow configuration YAML file. If not
                        provided, uses default locations.
  --enable-progress     Enable real-time progress visualization with Rich UI
                        (default: True).
  --no-progress         Disable real-time progress visualization.
```

## æ•…éšœæ’é™¤

### é—®é¢˜ï¼šæ‰¾ä¸åˆ° schema æ–‡ä»¶
```bash
FileNotFoundError: Schema file not found: ...
```

**è§£å†³æ–¹æ¡ˆ**ï¼šç¡®ä¿è·¯å¾„æ­£ç¡®ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹äºå·¥ä½œç›®å½•çš„è·¯å¾„ï¼š
```bash
python main.py --schema "$(pwd)/mcp_servers/domain/file.json"
```

### é—®é¢˜ï¼šAPI å¯†é’¥æœªè®¾ç½®
```bash
ValueError: API key is required. Please set one of the following environment variables: ...
```

**è§£å†³æ–¹æ¡ˆ**ï¼šè®¾ç½®ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨ `--api-key` å‚æ•°ï¼š
```bash
export DEEPSEEK_API_KEY="your-key"
# æˆ–
python main.py --api-key "your-key" --schema "..."
```

### é—®é¢˜ï¼šè¿›åº¦æ˜¾ç¤ºé”™ä¹±
å¦‚æœç»ˆç«¯ä¸æ”¯æŒ Rich UIï¼š
```bash
python main.py --no-progress --schema "..."
```

### é—®é¢˜ï¼šAgent è½®æ¬¡ä¸è¶³
```bash
RuntimeError: Code review did not pass after multiple iterations...
```

**è§£å†³æ–¹æ¡ˆ**ï¼šå¢åŠ æœ€å¤§è½®æ¬¡ï¼š
```bash
python main.py --max-turns 40 --schema "..."
```

## é«˜çº§ç”¨æ³•

### æ‰¹é‡å¤„ç†å¤šä¸ª schema

åˆ›å»ºè„šæœ¬ `batch_process.sh`ï¼š

```bash
#!/bin/bash

SCHEMAS=(
  "mcp_servers/Time & Calendar/google-calendar.json"
  "mcp_servers/Social_Media/twitter.json"
  "mcp_servers/Travel_Maps/airbnb.json"
)

for schema in "${SCHEMAS[@]}"; do
  echo "Processing: $schema"
  python main.py \
    --schema "$schema" \
    --no-progress \
    --max-turns 30 \
    2>&1 | tee "logs/$(basename "$schema" .json).log"
done
```

### CI/CD é›†æˆ

```yaml
# .github/workflows/generate.yml
name: Generate MCP Servers

on: [push]

jobs:
  generate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install -e .
      
      - name: Generate servers
        env:
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        run: |
          python main.py \
            --schema "mcp_servers/schema.json" \
            --no-progress \
            --max-turns 30
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v2
        with:
          name: generated-servers
          path: generated/
```

## å‚è€ƒèµ„æ–™

- [ä¸»æ–‡æ¡£](../README.md)
- [å¯è§‚æµ‹æ€§åŠŸèƒ½](OBSERVABILITY.md)
- [ä½¿ç”¨ç¤ºä¾‹](OBSERVABILITY_EXAMPLE.md)
- [é…ç½®æ–‡ä»¶è¯´æ˜](../workflow/config/default.yaml)

