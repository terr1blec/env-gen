{
  "labels": {
    "analysis": "The Omi API Server is designed to facilitate interaction with Omi conversations and memories via a standardized MCP interface. Its core functionality revolves around managing conversational data and user memories within LLM workflows. The available tools allow for reading, creating, and managing conversations and memories, which indicates a focus on data retrieval, storage, and contextual interaction. The server integrates with MCP-compatible clients like Claude and Cursor, enhancing contextual understanding and workflow efficiency.",
    "reasoning": "The primary label \"Memory Management\" was chosen because the server heavily focuses on managing conversations and memories, which aligns with data storage and retrieval capabilities. The secondary label \"Development Tools\" was selected due to its integration with LLM workflows and MCP-compatible clients, which suggests utility in developer environments. No custom label is needed as the server's functionality is well-covered by the predefined categories.",
    "primary_label": "Memory Management",
    "secondary_labels": [
      "Development Tools"
    ],
    "custom_label": null,
    "is_connected": false,
    "is_remote_tool_valid": false,
    "featured_server": false
  },
  "metadata": {
    "server_id": 2005,
    "server_name": "Omi API Server",
    "rank_by_usage": 2006,
    "usage_count": "Not available",
    "original_file": "../crawler/smithery/@leonskenidy_omi-mcp.json",
    "mode": "smithery",
    "timestamp": 1751941824,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@leonskenidy/omi-mcp/mcp?api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": false,
      "error": "unhandled errors in a TaskGroup (1 sub-exception)",
      "tools": [],
      "tool_count": 0,
      "tool_names": []
    },
    "server_info_crawled": {
      "id": 2005,
      "name": "Omi API Server",
      "author": "@leonskenidy/omi-mcp",
      "overview": "Provide seamless access to Omi conversations and memories through a standardized MCP interface. Enable users to read, create, and manage conversations and memories efficiently within their LLM workflows. Integrate easily with Claude, Cursor, and other MCP-compatible clients to enhance contextual understanding and interaction.",
      "repository_url": "https://github.com/leonskenidy/omi-mcp",
      "homepage": "https://smithery.ai/server/@leonskenidy/omi-mcp",
      "remote_or_local": "Remote",
      "license": "Smithery",
      "usage_count": "Not available",
      "success_rate": "Not available",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@leonskenidy_omi-mcp.json",
      "tools_count": 4,
      "tools": [
        {
          "name": "read_omi_conversations",
          "description": "Deploy Server Omi API Server @leonskenidy/omi-mcp Try in Playground read_omi_conversations",
          "parameters": [
            {
              "name": "read_omi_conversations",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "read_omi_memories",
          "description": "Retrieves user memories from Omi with pagination options",
          "parameters": []
        },
        {
          "name": "create_omi_conversation",
          "description": "Creates a new Omi conversation with text content and metadata",
          "parameters": []
        },
        {
          "name": "create_omi_memories",
          "description": "Creates Omi memories by extracting from text or using explicit memory objects",
          "parameters": []
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nsmithery_api_key = \"\"\nurl = f\"https://server.smithery.ai/@leonskenidy/omi-mcp/mcp?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [
        {
          "name": "apiKey",
          "required": true,
          "description": "API key for Omi's API"
        }
      ],
      "python_sdk_config": "",
      "python_sdk_url": "https://server.smithery.ai/@leonskenidy/omi-mcp/mcp?api_key={smithery_api_key}"
    },
    "source_filename": "cf_2006.@leonskenidy_omi-mcp_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 1749
  }
}