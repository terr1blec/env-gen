{
  "labels": {
    "analysis": "The MCP Server, SushiMCP, enhances the performance of LLM models in generating code by providing improved context to AI IDEs. It focuses on fetching and managing documentation and API specifications through dedicated tools that locate and retrieve llms.txt files (documentation sources) and OpenAPI specs. The core functionality revolves around streamlining developer accessibility to relevant technical documentation, which aids in improving LLM code generation accuracy and efficiency.",
    "reasoning": "The primary functionality of the server is strongly tied to retrieving and managing technical documentation (llms.txt files) and API specifications (OpenAPI specs), which are crucial for developer productivity. This aligns closely with the \"Development Tools\" category. Additional focus on API interaction and specification retrieval justifies a secondary label of \"API Integration\". The server's unique aspect of enhancing LLM context for coding tasks suggests a custom label focused on developer toolchain augmentation.",
    "primary_label": "Development Tools",
    "secondary_labels": [
      "API Integration"
    ],
    "custom_label": "Developer Documentation Facilitator",
    "is_connected": true,
    "is_remote_tool_valid": false,
    "featured_server": false
  },
  "metadata": {
    "server_id": 1577,
    "server_name": "SushiMCP",
    "rank_by_usage": 1578,
    "usage_count": "Not available",
    "original_file": "../crawler/smithery/@maverickg59_sushimcp.json",
    "mode": "smithery",
    "timestamp": 1751938055,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@maverickg59/sushimcp/mcp?api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": true,
      "error": null,
      "tools": [
        {
          "name": "list_llms_txt_sources",
          "description": "This tool lists all available source urls where an llms.txt can be fetched. After reading the listed sources, use fetch_llms_txt to fetch any source that matches a technology in the instructions you received. Prefer llms.txt, but if llms.txt proves inadequate, check to see if other llms-full.txt or llms-mini.txt exist. When done, ask the user if they want to use non-MCP tools to search for documentation on any sources this tool could not find.",
          "input_schema": {
            "type": "object"
          },
          "annotations": null
        },
        {
          "name": "list_api_spec_sources",
          "description": "This tool lists all available source urls where an OpenAPI spec can be fetched.",
          "input_schema": {
            "type": "object"
          },
          "annotations": null
        },
        {
          "name": "fetch_llms_txt",
          "description": "Fetches the content of one or more llms.txt urls. Some llms.txt files compile a list of urls to other llms.txt file locations because listing their full documentation would bloat context. If the documentation you're looking for does not exist in the llms.txt, look for reference links to other llms.txt files and follow those.",
          "input_schema": {
            "type": "object",
            "properties": {
              "input": {
                "anyOf": [
                  {
                    "type": "object",
                    "properties": {
                      "url": {
                        "type": "string",
                        "format": "uri"
                      }
                    },
                    "required": [
                      "url"
                    ],
                    "additionalProperties": false
                  },
                  {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "format": "uri"
                    }
                  }
                ]
              }
            },
            "required": [
              "input"
            ],
            "additionalProperties": false,
            "$schema": "http://json-schema.org/draft-07/schema#"
          },
          "annotations": null
        },
        {
          "name": "fetch_openapi_spec",
          "description": "Fetches the content of one or more OpenAPI spec urls.",
          "input_schema": {
            "type": "object",
            "properties": {
              "input": {
                "anyOf": [
                  {
                    "type": "object",
                    "properties": {
                      "url": {
                        "type": "string",
                        "format": "uri"
                      }
                    },
                    "required": [
                      "url"
                    ],
                    "additionalProperties": false
                  },
                  {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "format": "uri"
                    }
                  }
                ]
              }
            },
            "required": [
              "input"
            ],
            "additionalProperties": false,
            "$schema": "http://json-schema.org/draft-07/schema#"
          },
          "annotations": null
        }
      ],
      "tool_count": 4,
      "tool_names": [
        "list_llms_txt_sources",
        "list_api_spec_sources",
        "fetch_llms_txt",
        "fetch_openapi_spec"
      ]
    },
    "server_info_crawled": {
      "id": 1577,
      "name": "SushiMCP",
      "author": "@maverickg59/sushimcp",
      "overview": "Improve the performance of base and premium LLM models when generating code by delivering enhanced context to AI IDEs. Simplify integration with easy registration and configuration. Boost developer productivity with a streamlined model context protocol server.",
      "repository_url": "https://github.com/maverickg59/sushimcp",
      "homepage": "https://smithery.ai/server/@maverickg59/sushimcp",
      "remote_or_local": "Remote",
      "license": "AGPL-3.0",
      "usage_count": "Not available",
      "success_rate": "Not available",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@maverickg59_sushimcp.json",
      "tools_count": 4,
      "tools": [
        {
          "name": "list_llms_txt_sources",
          "description": "This tool lists all available source urls where an llms.txt can be fetched. After reading the listed sources, use fetch_llms_txt to fetch any source that matches a technology in the instructions you received. Prefer llms.txt, but if llms.txt proves inadequate, check to see if other llms-full.txt or llms-mini.txt exist. When done, ask the user if they want to use non-MCP tools to search for documentation on any sources this tool could not find.",
          "input_schema": {
            "type": "object"
          },
          "annotations": null
        },
        {
          "name": "list_api_spec_sources",
          "description": "This tool lists all available source urls where an OpenAPI spec can be fetched.",
          "input_schema": {
            "type": "object"
          },
          "annotations": null
        },
        {
          "name": "fetch_llms_txt",
          "description": "Fetches the content of one or more llms.txt urls. Some llms.txt files compile a list of urls to other llms.txt file locations because listing their full documentation would bloat context. If the documentation you're looking for does not exist in the llms.txt, look for reference links to other llms.txt files and follow those.",
          "input_schema": {
            "type": "object",
            "properties": {
              "input": {
                "anyOf": [
                  {
                    "type": "object",
                    "properties": {
                      "url": {
                        "type": "string",
                        "format": "uri"
                      }
                    },
                    "required": [
                      "url"
                    ],
                    "additionalProperties": false
                  },
                  {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "format": "uri"
                    }
                  }
                ]
              }
            },
            "required": [
              "input"
            ],
            "additionalProperties": false,
            "$schema": "http://json-schema.org/draft-07/schema#"
          },
          "annotations": null
        },
        {
          "name": "fetch_openapi_spec",
          "description": "Fetches the content of one or more OpenAPI spec urls.",
          "input_schema": {
            "type": "object",
            "properties": {
              "input": {
                "anyOf": [
                  {
                    "type": "object",
                    "properties": {
                      "url": {
                        "type": "string",
                        "format": "uri"
                      }
                    },
                    "required": [
                      "url"
                    ],
                    "additionalProperties": false
                  },
                  {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "format": "uri"
                    }
                  }
                ]
              }
            },
            "required": [
              "input"
            ],
            "additionalProperties": false,
            "$schema": "http://json-schema.org/draft-07/schema#"
          },
          "annotations": null
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nsmithery_api_key = \"\"\nurl = f\"https://server.smithery.ai/@maverickg59/sushimcp/mcp?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [],
      "python_sdk_config": "",
      "python_sdk_url": "https://server.smithery.ai/@maverickg59/sushimcp/mcp?api_key={smithery_api_key}"
    },
    "source_filename": "1578.@maverickg59_sushimcp_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 1442
  }
}