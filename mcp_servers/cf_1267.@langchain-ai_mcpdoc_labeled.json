{
  "labels": {
    "analysis": "The MCP Server is designed to manage and retrieve documentation sources, allowing users to list available documentation files (via URLs or local paths) and fetch content from those sources. It enhances transparency in LLM interactions by enabling users to audit tool calls and context. The primary use case revolves around documentation management, retrieval, and integration with development workflows.",
    "reasoning": "The server's core functionality revolves around listing and fetching documentation, which aligns with file management and data retrieval. Since it's tied to documentation and development tools, it also fits into the development tools category. No secondary labels are necessary as these two categories sufficiently cover its scope.",
    "primary_label": "File Management",
    "secondary_labels": [
      "Development Tools"
    ],
    "custom_label": "Documentation Assistant",
    "is_connected": false,
    "is_remote_tool_valid": false,
    "featured_server": false
  },
  "metadata": {
    "server_id": 1266,
    "server_name": "Documentation Server",
    "rank_by_usage": 1267,
    "usage_count": "Not available",
    "original_file": "../crawler/smithery/@langchain-ai_mcpdoc.json",
    "mode": "smithery",
    "timestamp": 1751941824,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@langchain-ai/mcpdoc/mcp?api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": false,
      "error": "unhandled errors in a TaskGroup (1 sub-exception)",
      "tools": [],
      "tool_count": 0,
      "tool_names": []
    },
    "server_info_crawled": {
      "id": 1266,
      "name": "Documentation Server",
      "author": "@langchain-ai/mcpdoc",
      "overview": "Provide a user-defined list of llms.txt files and a simple fetch_docs tool to read URLs within those files. This allows users to audit tool calls and the context returned, enhancing transparency and control over LLM interactions. Connect seamlessly with various IDEs and applications to enrich your development experience.",
      "repository_url": "https://github.com/langchain-ai/mcpdoc",
      "homepage": "https://smithery.ai/server/@langchain-ai/mcpdoc",
      "remote_or_local": "Remote",
      "license": "MIT",
      "usage_count": "Not available",
      "success_rate": "Not available",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@langchain-ai_mcpdoc.json",
      "tools_count": 2,
      "tools": [
        {
          "name": "list_doc_sources",
          "description": "List all available documentation sources.\n\n        This is the first tool you should call in the documentation workflow.\n        It provides URLs to llms.txt files or local file paths that the user has made available.\n\n        Returns:\n            A string containing a formatted list of documentation sources with their URLs or file paths",
          "parameters": []
        },
        {
          "name": "fetch_docs",
          "description": "Fetch and parse documentation from a given URL or local file. Use this tool after list_doc_sources to:\n1. First fetch the llms.",
          "parameters": []
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nsmithery_api_key = \"\"\nurl = f\"https://server.smithery.ai/@langchain-ai/mcpdoc/mcp?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [],
      "python_sdk_config": "",
      "python_sdk_url": "https://server.smithery.ai/@langchain-ai/mcpdoc/mcp?api_key={smithery_api_key}"
    },
    "source_filename": "cf_1267.@langchain-ai_mcpdoc_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 1210
  }
}