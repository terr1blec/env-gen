{
  "labels": {
    "analysis": "The CoConuT Continuous Chain of Thought Server is designed to enhance language model reasoning through structured, multi-branch thinking processes. It enables quality analysis, cycle detection, and persistent interaction history while integrating into development environments (like Cursor IDE). The server appears to support iterative problem-solving, documentation of reasoning steps, and continuous improvement of LLM outputs through its booster tools (Booster, Booster_Storage, Booster_Analyser, Booster_Steps).",
    "reasoning": "The primary label \"Development Tools\" reflects the server's integration with IDEs and focus on structured problem-solving, which is core to development workflows. The secondary label \"AI/ML Tools\" highlights its specialization in language model reasoning. The custom label \"Conscious LLM Reasoning\" captures its unique focus on continuous, documentary, and analytically enhanced chain-of-thought processes.",
    "primary_label": "Development Tools",
    "secondary_labels": [
      "AI/ML Tools"
    ],
    "custom_label": "Conscious LLM Reasoning",
    "is_connected": false,
    "is_remote_tool_valid": false,
    "featured_server": false
  },
  "metadata": {
    "server_id": 2373,
    "server_name": "CoConuT Continuous Chain of Thought Server",
    "rank_by_usage": 2374,
    "usage_count": "Not available",
    "original_file": "../crawler/smithery/@LLM-Booster_mcp-booster.json",
    "mode": "smithery",
    "timestamp": 1751941824,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@LLM-Booster/mcp-booster/mcp?api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": false,
      "error": "unhandled errors in a TaskGroup (1 sub-exception)",
      "tools": [],
      "tool_count": 0,
      "tool_names": []
    },
    "server_info_crawled": {
      "id": 2373,
      "name": "CoConuT Continuous Chain of Thought Server",
      "author": "@LLM-Booster/mcp-booster",
      "overview": "Enable continuous chain of thought reasoning with quality analysis and cycle detection for language models. Explore multiple reasoning branches, document conclusions, and persist interaction history automatically. Integrate seamlessly with IDEs like Cursor to enhance structured problem solving and reflection.",
      "repository_url": "https://github.com/LLM-Booster/mcp-booster",
      "homepage": "https://smithery.ai/server/@LLM-Booster/mcp-booster",
      "remote_or_local": "Remote",
      "license": "Smithery",
      "usage_count": "Not available",
      "success_rate": "Not available",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@LLM-Booster_mcp-booster.json",
      "tools_count": 4,
      "tools": [
        {
          "name": "Booster",
          "description": "Deploy Server CoConuT Continuous Chain of Thought Server @LLM-Booster/mcp-booster Try in Playground",
          "parameters": [
            {
              "name": "True",
              "required": false,
              "type": "string"
            },
            {
              "name": "False",
              "required": false,
              "type": "string"
            },
            {
              "name": "Call_Booster_Analyser",
              "required": true,
              "type": "string"
            }
          ]
        },
        {
          "name": "Booster_Storage",
          "description": "Description not available",
          "parameters": []
        },
        {
          "name": "Booster_Analyser",
          "description": "Description not available",
          "parameters": [
            {
              "name": "thoughts",
              "required": true,
              "type": "string"
            },
            {
              "name": "Add",
              "required": false,
              "type": "string"
            },
            {
              "name": "Item",
              "required": false,
              "type": "string"
            },
            {
              "name": "userQuery",
              "required": true,
              "type": "string"
            },
            {
              "name": "projectPath",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "Booster_Steps",
          "description": "Description not available",
          "parameters": [
            {
              "name": "steps",
              "required": true,
              "type": "string"
            },
            {
              "name": "Add",
              "required": false,
              "type": "string"
            },
            {
              "name": "Item",
              "required": false,
              "type": "string"
            },
            {
              "name": "title",
              "required": true,
              "type": "string"
            },
            {
              "name": "projectPath",
              "required": true,
              "type": "string"
            },
            {
              "name": "taskDescription",
              "required": true,
              "type": "string"
            }
          ]
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nsmithery_api_key = \"\"\nurl = f\"https://server.smithery.ai/@LLM-Booster/mcp-booster/mcp?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [
        {
          "name": "apiKey",
          "required": true,
          "description": "API key for CoConuT endpoint"
        }
      ],
      "python_sdk_config": "",
      "python_sdk_url": "https://server.smithery.ai/@LLM-Booster/mcp-booster/mcp?api_key={smithery_api_key}"
    },
    "source_filename": "cf_2374.@LLM-Booster_mcp-booster_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 2033
  }
}