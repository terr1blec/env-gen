{
  "labels": {
    "analysis": "The MCP Server specializes in advanced web scraping, crawling, and content extraction, with a strong emphasis on structured data retrieval and AI-assisted analysis. It supports JavaScript rendering, batch processing, rate limiting, and integration with LLM-powered tools. The server is particularly useful for deep research, structured data extraction, and efficient web data integration through automated and smart filtering.",
    "reasoning": "The primary label \"Web Search & Research\" was chosen because the server's core functionality revolves around gathering information from the web, conducting research, and extracting structured data. \"Data Analysis & Processing\" is selected as a secondary label due to the server's capabilities in data transformation and AI-assisted extraction. Another secondary label, \"Browser Automation,\" is appropriate given its tools for automated crawling and scraping. The custom label \"AI-Powered Web Data Extraction\" is added to highlight the unique combination of traditional web scraping with LLM integration for enhanced data retrieval.",
    "primary_label": "Web Search & Research",
    "secondary_labels": [
      "Data Analysis & Processing",
      "Browser Automation"
    ],
    "custom_label": "AI-Powered Web Data Extraction",
    "is_connected": false,
    "is_remote_tool_valid": false,
    "featured_server": false
  },
  "metadata": {
    "server_id": 44,
    "server_name": "Firecrawl Web Scraping Server",
    "rank_by_usage": 45,
    "usage_count": "2,625",
    "original_file": "../crawler/smithery/@Krieg2065_firecrawl-mcp-server.json",
    "mode": "smithery",
    "timestamp": 1751941824,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@Krieg2065/firecrawl-mcp-server/mcp?api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": false,
      "error": "unhandled errors in a TaskGroup (1 sub-exception)",
      "tools": [],
      "tool_count": 0,
      "tool_names": []
    },
    "server_info_crawled": {
      "id": 44,
      "name": "Firecrawl Web Scraping Server",
      "author": "@Krieg2065/firecrawl-mcp-server",
      "overview": "Enable advanced web scraping, crawling, and content extraction with support for JavaScript rendering, batch processing, and smart filtering. Perform deep research and structured data extraction using LLM-powered tools. Monitor credit usage and handle rate limits automatically for efficient and reliable web data integration.",
      "repository_url": "https://github.com/Krieg2065/firecrawl-mcp-server",
      "homepage": "https://smithery.ai/server/@Krieg2065/firecrawl-mcp-server",
      "remote_or_local": "Remote",
      "license": "MIT",
      "usage_count": "2,625",
      "success_rate": "99.88%",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@Krieg2065_firecrawl-mcp-server.json",
      "tools_count": 10,
      "tools": [
        {
          "name": "firecrawl_scrape",
          "description": "Deploy Server Firecrawl Web Scraping Server @Krieg2065/firecrawl-mcp-server Try in Playground firecrawl_scrape",
          "parameters": [
            {
              "name": "firecrawl_scrape",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "firecrawl_map",
          "description": "Discover URLs from a starting point. Can use both sitemap.xml and HTML link discovery.",
          "parameters": [
            {
              "name": "firecrawl_map",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "firecrawl_crawl",
          "description": "Start an asynchronous crawl of multiple pages from a starting URL. Supports depth control, path filtering, and webhook notifications.",
          "parameters": [
            {
              "name": "True",
              "required": false,
              "type": "string"
            },
            {
              "name": "False",
              "required": false,
              "type": "string"
            },
            {
              "name": "deduplicateSimilarURLs",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "firecrawl_batch_scrape",
          "description": "Scrape multiple URLs in batch mode. Returns a job ID that can be used to check status.",
          "parameters": [
            {
              "name": "firecrawl_batch_scrape",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "firecrawl_check_batch_status",
          "description": "Check the status of a batch scraping job.",
          "parameters": [
            {
              "name": "firecrawl_check_batch_status",
              "required": false,
              "type": "string"
            },
            {
              "name": "id",
              "required": true,
              "type": "string"
            }
          ]
        },
        {
          "name": "firecrawl_check_crawl_status",
          "description": "Check the status of a crawl job.",
          "parameters": [
            {
              "name": "firecrawl_check_crawl_status",
              "required": false,
              "type": "string"
            },
            {
              "name": "id",
              "required": true,
              "type": "string"
            }
          ]
        },
        {
          "name": "firecrawl_search",
          "description": "Search and retrieve content from web pages with optional scraping. Returns SERP results by default (url, title, description) or full page content when scrapeOptions are provided.",
          "parameters": [
            {
              "name": "firecrawl_search",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "firecrawl_extract",
          "description": "Extract structured information from web pages using LLM. Supports both cloud AI and self-hosted LLM extraction.",
          "parameters": [
            {
              "name": "firecrawl_extract",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "firecrawl_deep_research",
          "description": "Conduct deep research on a query using web crawling, search, and AI analysis.",
          "parameters": [
            {
              "name": "firecrawl_deep_research",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "firecrawl_generate_llmstxt",
          "description": "Generate standardized LLMs.txt file for a given URL, which provides context about how LLMs should interact with the website.",
          "parameters": [
            {
              "name": "firecrawl_generate_llmstxt",
              "required": false,
              "type": "string"
            }
          ]
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nsmithery_api_key = \"\"\nurl = f\"https://server.smithery.ai/@Krieg2065/firecrawl-mcp-server/mcp?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [
        {
          "name": "fireCrawlApiKey",
          "required": true,
          "description": "Your Firecrawl API key. Required for cloud API usage."
        }
      ],
      "python_sdk_config": "",
      "python_sdk_url": "https://server.smithery.ai/@Krieg2065/firecrawl-mcp-server/mcp?api_key={smithery_api_key}"
    },
    "source_filename": "cf_0045.@Krieg2065_firecrawl-mcp-server_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 44
  }
}