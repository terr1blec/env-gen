{
  "labels": {
    "analysis": "The MCP Crew Risk server is designed to evaluate the compliance and risk factors associated with web crawling activities. It assesses legal, social ethics, and technical dimensions to help developers and operators plan crawler strategies that avoid legal disputes, negative social impacts, and technical issues. The available tool (assess-crew-risk) focuses on compliance detection and risk mitigation for web crawling.",
    "reasoning": "The primary functionality of the server is to assess compliance and risks related to web crawling, which aligns best with the \"Browser Automation\" category as it is directly related to web scraping and automated browsing. Additionally, the server's focus on legal and ethical compliance suggests relevance to \"Security & Authentication\" and \"Web Search & Research\" categories. Custom label \"Crawler Compliance Monitoring\" is added to highlight the unique aspect of compliance evaluation specific to crawling operations.",
    "primary_label": "Browser Automation",
    "secondary_labels": [
      "Security & Authentication",
      "Web Search & Research"
    ],
    "custom_label": "Crawler Compliance Monitoring",
    "is_connected": true,
    "is_remote_tool_valid": false,
    "featured_server": false
  },
  "metadata": {
    "server_id": 1135,
    "server_name": "mcp-crew-risk",
    "rank_by_usage": 1136,
    "usage_count": "1",
    "original_file": "../crawler/smithery/@deeppath-ai_mcp-crew-risk.json",
    "mode": "smithery",
    "timestamp": 1751938055,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@deeppath-ai/mcp-crew-risk/mcp?api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": true,
      "error": null,
      "tools": [
        {
          "name": "assess-crew-risk",
          "description": "This system evaluates the compliance and potential risks associated with web crawling activities. It is designed to assist developers, legal teams, and data professionals in ensuring that their crawlers operate within acceptable technical, legal, and ethical boundaries.",
          "input_schema": {
            "type": "object",
            "properties": {
              "url": {
                "type": "string",
                "description": "Web page URL, for example: https://www.xxx.com"
              }
            },
            "required": [
              "url"
            ],
            "additionalProperties": false,
            "$schema": "http://json-schema.org/draft-07/schema#"
          },
          "annotations": null
        }
      ],
      "tool_count": 1,
      "tool_names": [
        "assess-crew-risk"
      ]
    },
    "server_info_crawled": {
      "id": 1135,
      "name": "mcp-crew-risk",
      "author": "@deeppath-ai/mcp-crew-risk",
      "overview": "This framework aims to provide crawler developers and operators with a comprehensive automated compliance detection toolset to evaluate the crawler-friendliness and potential risks of target websites. It covers three major dimensions: legal, social ethics, and technical aspects. Through multi-level risk warnings and specific recommendations, it helps plan crawler strategies reasonably to avoid legal disputes and negative social impacts while improving technical stability and efficiency.",
      "repository_url": "https://github.com/deeppath-ai/mcp-crew-risk",
      "homepage": "https://smithery.ai/server/@deeppath-ai/mcp-crew-risk",
      "remote_or_local": "Remote",
      "license": "MIT",
      "usage_count": "1",
      "success_rate": "Not available",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@deeppath-ai_mcp-crew-risk.json",
      "tools_count": 1,
      "tools": [
        {
          "name": "assess-crew-risk",
          "description": "This system evaluates the compliance and potential risks associated with web crawling activities. It is designed to assist developers, legal teams, and data professionals in ensuring that their crawlers operate within acceptable technical, legal, and ethical boundaries.",
          "input_schema": {
            "type": "object",
            "properties": {
              "url": {
                "type": "string",
                "description": "Web page URL, for example: https://www.xxx.com"
              }
            },
            "required": [
              "url"
            ],
            "additionalProperties": false,
            "$schema": "http://json-schema.org/draft-07/schema#"
          },
          "annotations": null
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nsmithery_api_key = \"\"\nurl = f\"https://server.smithery.ai/@deeppath-ai/mcp-crew-risk/mcp?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [],
      "python_sdk_config": "",
      "python_sdk_url": "https://server.smithery.ai/@deeppath-ai/mcp-crew-risk/mcp?api_key={smithery_api_key}"
    },
    "source_filename": "1136.@deeppath-ai_mcp-crew-risk_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 1113
  }
}