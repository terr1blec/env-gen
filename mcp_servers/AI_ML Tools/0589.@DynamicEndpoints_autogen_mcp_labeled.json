{
  "labels": {
    "analysis": "The MCP Server is designed to create and manage AI agents that can collaborate and solve problems through natural language interactions. It allows for the creation of multi-agent conversations, orchestration of group chats, and includes tools for real-time streaming workflows and chat sessions. The primary functionality revolves around AI agent management, coordination, and interaction, with a focus on seamless communication and error handling between agents.",
    "reasoning": "The primary label \"AI/ML Tools\" is chosen because the server's core functionality is centered around creating and managing AI agents, which falls under machine learning and AI interaction. The secondary label \"Communication Tools\" is included due to the emphasis on multi-agent conversations and orchestrating group chats, which involves messaging and interaction. The predefined categories do not require a custom label as the server's functionality is well-covered by the existing categories.",
    "primary_label": "AI/ML Tools",
    "secondary_labels": [
      "Communication Tools"
    ],
    "custom_label": null,
    "is_connected": true,
    "is_remote_tool_valid": true,
    "featured_server": false
  },
  "metadata": {
    "server_id": 588,
    "server_name": "AutoGen Server",
    "rank_by_usage": 589,
    "usage_count": "18",
    "original_file": "../crawler/smithery/@DynamicEndpoints_autogen_mcp.json",
    "mode": "smithery",
    "timestamp": 1751938055,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@DynamicEndpoints/autogen_mcp/mcp?config=eyJvcGVuYWlBcGlLZXkiOiAiIn0=&api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": true,
      "error": null,
      "tools": [
        {
          "name": "create_streaming_workflow",
          "description": "Create a workflow with real-time streaming",
          "input_schema": {
            "type": "object",
            "properties": {
              "workflow_name": {
                "type": "string",
                "description": "Name for the workflow"
              },
              "workflow_type": {
                "type": "string",
                "description": "Type of workflow"
              },
              "agents": {
                "type": "array",
                "description": "List of agent configurations"
              },
              "streaming": {
                "type": "boolean",
                "description": "Enable streaming"
              }
            },
            "required": [
              "workflow_name",
              "workflow_type",
              "agents"
            ]
          },
          "annotations": null
        },
        {
          "name": "start_streaming_chat",
          "description": "Start a streaming chat session",
          "input_schema": {
            "type": "object",
            "properties": {
              "agent_name": {
                "type": "string",
                "description": "Name of the agent"
              },
              "message": {
                "type": "string",
                "description": "Initial message"
              },
              "streaming": {
                "type": "boolean",
                "description": "Enable streaming"
              }
            },
            "required": [
              "agent_name",
              "message"
            ]
          },
          "annotations": null
        },
        {
          "name": "create_agent",
          "description": "Create a new AutoGen agent",
          "input_schema": {
            "type": "object",
            "properties": {
              "name": {
                "type": "string",
                "description": "Unique name for the agent"
              },
              "type": {
                "type": "string",
                "description": "Agent type"
              },
              "system_message": {
                "type": "string",
                "description": "System message"
              },
              "llm_config": {
                "type": "object",
                "description": "LLM configuration"
              }
            },
            "required": [
              "name",
              "type"
            ]
          },
          "annotations": null
        },
        {
          "name": "execute_workflow",
          "description": "Execute a workflow with streaming support",
          "input_schema": {
            "type": "object",
            "properties": {
              "workflow_name": {
                "type": "string",
                "description": "Workflow name"
              },
              "input_data": {
                "type": "object",
                "description": "Input data"
              },
              "streaming": {
                "type": "boolean",
                "description": "Enable streaming"
              }
            },
            "required": [
              "workflow_name",
              "input_data"
            ]
          },
          "annotations": null
        }
      ],
      "tool_count": 4,
      "tool_names": [
        "create_streaming_workflow",
        "start_streaming_chat",
        "create_agent",
        "execute_workflow"
      ]
    },
    "server_info_crawled": {
      "id": 588,
      "name": "AutoGen Server",
      "author": "@DynamicEndpoints/autogen_mcp",
      "overview": "Create and manage AI agents that collaborate and solve problems through natural language interactions. Enable multi-agent conversations and orchestrate group chats with customizable configurations. Enhance your applications with built-in error handling and response validation for seamless communication between agents.",
      "repository_url": "https://github.com/DynamicEndpoints/Autogen_MCP",
      "homepage": "https://smithery.ai/server/@DynamicEndpoints/autogen_mcp",
      "remote_or_local": "Remote",
      "license": "MIT",
      "usage_count": "18",
      "success_rate": "Not available",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@DynamicEndpoints_autogen_mcp.json",
      "tools_count": 4,
      "tools": [
        {
          "name": "create_streaming_workflow",
          "description": "Create a workflow with real-time streaming",
          "input_schema": {
            "type": "object",
            "properties": {
              "workflow_name": {
                "type": "string",
                "description": "Name for the workflow"
              },
              "workflow_type": {
                "type": "string",
                "description": "Type of workflow"
              },
              "agents": {
                "type": "array",
                "description": "List of agent configurations"
              },
              "streaming": {
                "type": "boolean",
                "description": "Enable streaming"
              }
            },
            "required": [
              "workflow_name",
              "workflow_type",
              "agents"
            ]
          },
          "annotations": null
        },
        {
          "name": "start_streaming_chat",
          "description": "Start a streaming chat session",
          "input_schema": {
            "type": "object",
            "properties": {
              "agent_name": {
                "type": "string",
                "description": "Name of the agent"
              },
              "message": {
                "type": "string",
                "description": "Initial message"
              },
              "streaming": {
                "type": "boolean",
                "description": "Enable streaming"
              }
            },
            "required": [
              "agent_name",
              "message"
            ]
          },
          "annotations": null
        },
        {
          "name": "create_agent",
          "description": "Create a new AutoGen agent",
          "input_schema": {
            "type": "object",
            "properties": {
              "name": {
                "type": "string",
                "description": "Unique name for the agent"
              },
              "type": {
                "type": "string",
                "description": "Agent type"
              },
              "system_message": {
                "type": "string",
                "description": "System message"
              },
              "llm_config": {
                "type": "object",
                "description": "LLM configuration"
              }
            },
            "required": [
              "name",
              "type"
            ]
          },
          "annotations": null
        },
        {
          "name": "execute_workflow",
          "description": "Execute a workflow with streaming support",
          "input_schema": {
            "type": "object",
            "properties": {
              "workflow_name": {
                "type": "string",
                "description": "Workflow name"
              },
              "input_data": {
                "type": "object",
                "description": "Input data"
              },
              "streaming": {
                "type": "boolean",
                "description": "Enable streaming"
              }
            },
            "required": [
              "workflow_name",
              "input_data"
            ]
          },
          "annotations": null
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nconfig = {\n  \"openaiApiKey\": \"\"\n}\n# Encode config in base64\nconfig_b64 = base64.b64encode(json.dumps(config).encode()).decode()\nsmithery_api_key = \"\"\n\n# Create server URL\nurl = f\"https://server.smithery.ai/@DynamicEndpoints/autogen_mcp/mcp?config={config_b64}&api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [],
      "python_sdk_config": "{\n  \"openaiApiKey\": \"\"\n}",
      "python_sdk_url": "https://server.smithery.ai/@DynamicEndpoints/autogen_mcp/mcp?config={config_b64}&api_key={smithery_api_key}"
    },
    "source_filename": "0589.@DynamicEndpoints_autogen_mcp_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 575
  }
}