{
  "labels": {
    "analysis": "The MCP Server described here focuses on enhancing AI reasoning through a process called \"Chain-of-Recursive-Thoughts.\" It allows AI models to argue with themselves repeatedly, exploring multiple perspectives and improving response quality. The tools provided enable recursive self-critique, multi-LLM inference (using different models for diverse viewpoints), and detailed reasoning outputs including history and evaluation processes. This server integrates with MCP hosts to provide more accurate and insightful AI responses.",
    "reasoning": "The primary function of this server is to improve AI reasoning quality through recursive thinking and multi-LLM perspectives, which aligns most closely with AI-powered features and enhanced cognitive processing. Secondary labels are included for natural language processing and multi-model inference capabilities. No custom label is needed as predefined categories sufficiently cover the functionality.",
    "primary_label": "AI/ML Tools",
    "secondary_labels": [
      "Data Analysis & Processing",
      "Development Tools"
    ],
    "custom_label": null,
    "is_connected": false,
    "is_remote_tool_valid": false,
    "featured_server": false
  },
  "metadata": {
    "server_id": 1569,
    "server_name": "Chain-of-Recursive-Thoughts Server",
    "rank_by_usage": 1570,
    "usage_count": "Not available",
    "original_file": "../crawler/smithery/@KunihiroS_cort-mcp.json",
    "mode": "smithery",
    "timestamp": 1751941824,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@KunihiroS/cort-mcp/mcp?api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": false,
      "error": "unhandled errors in a TaskGroup (1 sub-exception)",
      "tools": [],
      "tool_count": 0,
      "tool_names": []
    },
    "server_info_crawled": {
      "id": 1569,
      "name": "Chain-of-Recursive-Thoughts Server",
      "author": "@KunihiroS/cort-mcp",
      "overview": "Enable AI to think harder by making it argue with itself repeatedly, improving reasoning quality through recursive self-critique. Utilize multi-LLM inference to explore diverse model perspectives and enhanced evaluation prompts for better response selection. Integrate seamlessly with your MCP host to leverage advanced AI thought processes for more accurate and insightful outputs.",
      "repository_url": "https://github.com/KunihiroS/cort-mcp",
      "homepage": "https://smithery.ai/server/@KunihiroS/cort-mcp",
      "remote_or_local": "Remote",
      "license": "MIT",
      "usage_count": "Not available",
      "success_rate": "Not available",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@KunihiroS_cort-mcp.json",
      "tools_count": 8,
      "tools": [
        {
          "name": "cort.think.simple",
          "description": "Deploy Server Chain-of-Recursive-Thoughts Server @KunihiroS/cort-mcp Try in Playground cort.think.simple",
          "parameters": []
        },
        {
          "name": "cort.think.simple.neweval",
          "description": "Return a simple recursive thinking AI response (new evaluation prompt version).",
          "parameters": []
        },
        {
          "name": "cort.think.details",
          "description": "Returns a recursive thinking AI response with full reasoning details.",
          "parameters": []
        },
        {
          "name": "cort.think.details.neweval",
          "description": "Returns a recursive thinking AI response with full reasoning details (new evaluation prompt version). Features: - Provides a recursive thinking AI response and the reasoning process/history (YAML format) for the given prompt.",
          "parameters": []
        },
        {
          "name": "cort.think.simple_mixed_llm",
          "description": "Generate recursive thinking AI response using a different LLM (provider/model) for each alternative. No history/details output. Parameters: prompt (str, required). model/provider cannot be specified (randomly selected internally). Provider/model info for each alternative is always logged and included in the output.",
          "parameters": []
        },
        {
          "name": "cort.think.simple_mixed_llm.neweval",
          "description": "Generate recursive thinking AI response using a different LLM (provider/model) for each alternative. No history/details output. (new evaluation prompt version)",
          "parameters": [
            {
              "name": "prompt",
              "required": true,
              "type": "string"
            }
          ]
        },
        {
          "name": "cort.think.details_mixed_llm",
          "description": "Generate recursive thinking AI response with full history, using a different LLM (provider/model) for each alternative. Parameters: prompt (str, required). model/provider cannot be specified (randomly selected internally). Provider/model info for each alternative is always logged and included in the output and history.",
          "parameters": []
        },
        {
          "name": "cort.think.details_mixed_llm.neweval",
          "description": "Generate recursive thinking AI response with full history, using a different LLM (provider/model) for each alternative. (new evaluation prompt version)",
          "parameters": []
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nsmithery_api_key = \"\"\nurl = f\"https://server.smithery.ai/@KunihiroS/cort-mcp/mcp?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [
        {
          "name": "openrouterApiKey",
          "required": true,
          "description": "API key for OpenRouter"
        }
      ],
      "python_sdk_config": "",
      "python_sdk_url": "https://server.smithery.ai/@KunihiroS/cort-mcp/mcp?api_key={smithery_api_key}"
    },
    "source_filename": "cf_1570.@KunihiroS_cort-mcp_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 1435
  }
}