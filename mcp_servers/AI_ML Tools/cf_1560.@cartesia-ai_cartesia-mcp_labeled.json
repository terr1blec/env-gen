{
  "labels": {
    "analysis": "The MCP Server's core functionality revolves around advanced voice processing, including text-to-speech conversion, voice cloning, localization, and audio modification. It enables seamless integration with clients for voice-related workflows. The tools focus on generating, modifying, and managing voice profiles, making it highly specialized for voice manipulation tasks.",
    "reasoning": "The primary label \"AI/ML Tools\" is chosen because the server leverages machine learning models to process and transform voice data. Secondary labels \"Content Creation\" and \"Communication Tools\" are relevant because the server aids in creating voice content and can be integrated into communication workflows. While there is unique functionality not covered by predefined categories, the predefined labels adequately capture the primary use cases.",
    "primary_label": "AI/ML Tools",
    "secondary_labels": [
      "Content Creation",
      "Communication Tools"
    ],
    "custom_label": null,
    "is_connected": false,
    "is_remote_tool_valid": false,
    "featured_server": false
  },
  "metadata": {
    "server_id": 1559,
    "server_name": "Cartesia Voice API Server",
    "rank_by_usage": 1560,
    "usage_count": "Not available",
    "original_file": "../crawler/smithery/@cartesia-ai_cartesia-mcp.json",
    "mode": "smithery",
    "timestamp": 1751941824,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@cartesia-ai/cartesia-mcp/mcp?api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": false,
      "error": "unhandled errors in a TaskGroup (1 sub-exception)",
      "tools": [],
      "tool_count": 0,
      "tool_names": []
    },
    "server_info_crawled": {
      "id": 1559,
      "name": "Cartesia Voice API Server",
      "author": "@cartesia-ai/cartesia-mcp",
      "overview": "Enable seamless interaction with Cartesia's voice API to localize speech, convert text to audio, infill voice clips, and modify audio files using different voices. Integrate effortlessly with clients like Claude Desktop and Cursor to enhance voice-related workflows. Leverage a free tier with generous monthly credits to experiment and deploy voice transformations.",
      "repository_url": "https://github.com/cartesia-ai/cartesia-mcp",
      "homepage": "https://smithery.ai/server/@cartesia-ai/cartesia-mcp",
      "remote_or_local": "Remote",
      "license": "Smithery",
      "usage_count": "Not available",
      "success_rate": "Not available",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@cartesia-ai_cartesia-mcp.json",
      "tools_count": 9,
      "tools": [
        {
          "name": "text_to_speech",
          "description": "Deploy Server Cartesia Voice API Server Claim Server @cartesia-ai/cartesia-mcp Try in Playground text_to_speech",
          "parameters": [
            {
              "name": "model_id",
              "required": false,
              "type": "string"
            },
            {
              "name": "str",
              "required": false,
              "type": "string"
            },
            {
              "name": "language",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "infill",
          "description": "Generate audio that smoothly connects two existing audio segments. This is useful for inserting new speech between existing speech segments while maintaining natural transitions. **The cost is 1 credit per character of the infill text plus a fixed cost of 300 credits.** Infilling is only available on `sonic-2` at this time. At least one of `left_audio` or `right_audio` must be provided. As with all generative models, there's some inherent variability, but here's some tips we recommend to get the best results from infill: - Use longer infill transcripts - This gives the model more flexibility to adapt to the rest of the audio - Target natural pauses in the audio when deciding where to clip - This means you don't need word-level timestamps to be as precise - Clip right up to the start and end of the audio segment you want infilled, keeping as much silence in the left/right audio segments as possible - This helps the model generate more natural transitions",
          "parameters": []
        },
        {
          "name": "voice_change",
          "description": "Takes an audio file of speech, and returns an audio file of speech spoken with the same intonation, but with a different voice.",
          "parameters": [
            {
              "name": "output_format_sample_rate",
              "required": false,
              "type": "string"
            },
            {
              "name": "int",
              "required": false,
              "type": "string"
            },
            {
              "name": "output_format_encoding",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "localize_voice",
          "description": "Create a new voice from an existing voice localized to a new language and dialect.",
          "parameters": [
            {
              "name": "name",
              "required": false,
              "type": "string"
            },
            {
              "name": "str",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "delete_voice",
          "description": "Parameters\n        ----------\n        voice_id : str\n            The ID of the voice to delete.\n\n        request_options : typing.Optional[RequestOptions]\n            Request-specific configuration.",
          "parameters": [
            {
              "name": "request_options",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "get_voice",
          "description": "Parameters\n        ----------\n        voice_id : str\n            The ID of the voice to get.\n\n        request_options : typing.Optional[RequestOptions]\n            Request-specific configuration.",
          "parameters": [
            {
              "name": "request_options",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "update_voice",
          "description": "Parameters\n        ----------\n        id : VoiceId\n\n        name : str\n            The name of the voice.\n\n        description : str\n            The description of the voice.\n\n        request_options : typing.Optional[RequestOptions]\n            Request-specific configuration.",
          "parameters": [
            {
              "name": "request_options",
              "required": false,
              "type": "string"
            }
          ]
        },
        {
          "name": "clone_voice",
          "description": "Clone a voice from an audio clip. This endpoint has two modes, stability and similarity. Similarity mode clones are more similar to the source clip, but may reproduce background noise. For these, use an audio clip about 5 seconds long. Stability mode clones are more stable, but may not sound as similar to the source clip. For these, use an audio clip 10-20 seconds long.",
          "parameters": []
        },
        {
          "name": "list_voices",
          "description": "Description not available",
          "parameters": [
            {
              "name": "limit",
              "required": false,
              "type": "string"
            },
            {
              "name": "starting_after",
              "required": false,
              "type": "string"
            }
          ]
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nsmithery_api_key = \"\"\nurl = f\"https://server.smithery.ai/@cartesia-ai/cartesia-mcp/mcp?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [
        {
          "name": "cartesiaApiKey",
          "required": true,
          "description": "Cartesia API key for authenticating with the Cartesia service"
        }
      ],
      "python_sdk_config": "",
      "python_sdk_url": "https://server.smithery.ai/@cartesia-ai/cartesia-mcp/mcp?api_key={smithery_api_key}"
    },
    "source_filename": "cf_1560.@cartesia-ai_cartesia-mcp_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 1428
  }
}