{
  "labels": {
    "analysis": "The MCP Server leverages the Wolfram Alpha LLM API to perform precise mathematical calculations, scientific computing, geographic information retrieval, and data analysis. It excels in handling natural language queries for factual information across various domains like history, art, astronomy, and more. The tools provided enable disambiguation of ambiguous queries through assumption-based clarifications, ensuring accurate results. This server bridges the gap between natural language queries and computational knowledge, making it particularly powerful for tasks requiring factual accuracy and scientific precision.",
    "reasoning": "The primary label \"Data Analysis & Processing\" is chosen because the server's core functionality revolves around analyzing and processing data to provide accurate, computation-driven results. The secondary labels \"Web Search & Research\" and \"AI/ML Tools\" are selected because the server enables research through natural language queries and utilizes advanced computational knowledge engine capabilities, respectively. No custom label is needed as the predefined categories sufficiently cover the server's functionality.",
    "primary_label": "Data Analysis & Processing",
    "secondary_labels": [
      "Web Search & Research",
      "AI/ML Tools"
    ],
    "custom_label": null,
    "is_connected": false,
    "is_remote_tool_valid": false,
    "featured_server": false
  },
  "metadata": {
    "server_id": 295,
    "server_name": "Wolfram Alpha LLM API",
    "rank_by_usage": 296,
    "usage_count": "114",
    "original_file": "../crawler/smithery/@henryhawke_wolfram-llm-mcp.json",
    "mode": "smithery",
    "timestamp": 1751941824,
    "remote_server_response": {
      "url": "https://server.smithery.ai/@henryhawke/wolfram-llm-mcp/mcp?api_key=8675feae-43b6-4170-beb5-d8fa5a938222&profile=monetary-anteater-CCaAaT",
      "is_success": false,
      "error": "unhandled errors in a TaskGroup (1 sub-exception)",
      "tools": [],
      "tool_count": 0,
      "tool_names": []
    },
    "server_info_crawled": {
      "id": 295,
      "name": "Wolfram Alpha LLM API",
      "author": "@henryhawke/wolfram-llm-mcp",
      "overview": "Given LLM's struggle with accurate mathematics and truth having the power of Wolfram Alpha is a huge improvement. Wolfram Alpha's LLM API computational knowledge engine through natural language queries to perform mathematical calculations, scientific computing, geographic information retrieval, and data analysis. Query facts about history, art, astronomy, and more with ease. Handle ambiguous queries with assumption-based clarifications for precise results.",
      "repository_url": "https://github.com/henryhawke/wolfram-llm-mcp",
      "homepage": "https://smithery.ai/server/@henryhawke/wolfram-llm-mcp",
      "remote_or_local": "Remote",
      "license": "Smithery",
      "usage_count": "114",
      "success_rate": "81.34%",
      "tags": [
        "search",
        "web",
        "api",
        "mcp"
      ],
      "categories": [
        "search",
        "api"
      ],
      "file_path": "../crawler/smithery/@henryhawke_wolfram-llm-mcp.json",
      "tools_count": 2,
      "tools": [
        {
          "name": "wolfram_query",
          "description": "Deploy Server Wolfram Alpha LLM API @henryhawke/wolfram-llm-mcp Try in Playground wolfram_query",
          "parameters": []
        },
        {
          "name": "wolfram_query_with_assumptions",
          "description": "Query Wolfram Alpha with specific assumptions when the initial query returns multiple interpretations. Use this when you need to clarify ambiguous queries.",
          "parameters": []
        }
      ],
      "python_sdk": "import mcp\nfrom mcp.client.streamable_http import streamablehttp_client\nimport json\nimport base64\n\nsmithery_api_key = \"\"\nurl = f\"https://server.smithery.ai/@henryhawke/wolfram-llm-mcp/mcp?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using HTTP client\n    async with streamablehttp_client(url) as (read_stream, write_stream, _):\n        async with mcp.ClientSession(read_stream, write_stream) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
      "configuration_schema": "",
      "smithery_configuration_requirements": [],
      "python_sdk_config": "",
      "python_sdk_url": "https://server.smithery.ai/@henryhawke/wolfram-llm-mcp/mcp?api_key={smithery_api_key}"
    },
    "source_filename": "cf_0296.@henryhawke_wolfram-llm-mcp_prepared.json",
    "processed_timestamp": 1753731940,
    "processing_mode": "smithery",
    "rank": 292
  }
}